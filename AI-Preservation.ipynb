{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba4d84e-ae47-475b-941d-462fd8f3c43b",
   "metadata": {},
   "source": [
    "# AI preservation\n",
    "\n",
    "This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks. AI preservation in general is still a largely unaddressed area of work, despite its rapid integration into digital preservation tools and workflows. Its use across domains of research makes it critical to the reproducibility of results, and its proper long-term management an essential condition for the future robustness of ECCCH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295e10c-b8e4-41c9-929a-1201023901e0",
   "metadata": {},
   "source": [
    "This approach employs a workflow as shown in the following picture.\n",
    "\n",
    "<img src=\"imgs/workflow.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d07a8-4080-4e43-8ccd-6c6c79d849c8",
   "metadata": {},
   "source": [
    "### The following sections describe a selection of examples of how we could address AI preservation from different perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68660bce-3a5b-461d-a11a-410e1101090d",
   "metadata": {},
   "source": [
    "#### Automatic generation of Model Cards and datasheets\n",
    "\n",
    "Model cards are files that are provided as part of models including provenance documentation such as how they were trained. Model cards are simple Markdown files with additional metadata. Model cards are essential for discoverability, reproducibilityHugging Face promotes its use  [https://huggingface.co/docs/hub/model-cards]. Previous work have addressed the [automatic generation of model cards](https://github.com/jiarui-liu/AutomatedModelCardGeneration) using LLMs and the text from the article and the code and documentation provided.\n",
    "\n",
    "A more advanced and detailed approach is [datasheets for cultural heritage datasets](https://pro.europeana.eu/project/datasheets-for-digital-cultural-heritage-working-group, an iniciative from Europeana to describe datasets and AI outputs. Datasheets include a structure to describe datasets that cover a wide diversity of categories such as authorship, provenance, biases, examples of use, contact, etc. The creation of datasheets from scratch requires a certain amount of time that could be leveraged by using LLM to create a preliminary draft. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ae7da01-836a-4a3e-8643-a50431a68a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO LLM training and assessment to generate datasheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b85c4-c2a0-44f6-93d8-de7542dd60b4",
   "metadata": {},
   "source": [
    "#### Storage of AI model and data\n",
    "\n",
    "By storing and preserving metadata, the AI model and the data used to train the model potential future users are enabled to reproduce the same results, using the same version of software libraries. An analysis is required in order to identify the amount of data required to store as well as the envelope or package in which all the data will be stored. Approaches from other fields will be analysed such as Web Archive and software development.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed88dfeb-54b8-4fae-9392-a4b3449f0b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO development of a reusable and standard package to enable AI preservation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7086b582-073d-492b-8fb7-e179f0154dde",
   "metadata": {},
   "source": [
    "### Integration with the ECCCH\n",
    "\n",
    "[ECHOES](https://www.echoes-eccch.eu/faq/) is building a federated Knowledge Graph to allow for high level integration of resources. It will also serve as an entry point for all queries and requests related to any kind of information available within the Cultural heritage Cloud. The Knowledge Graph will use the proposed Heritage Digital Twin Ontology (HDTO) to unify descriptions and facilitate query and navigation. The current version of the ECHOES HDTO is available [here](https://www.echoes-eccch.eu/wp-content/uploads/2025/06/ECHOES_HDT_Ontology.pdf). The main vocabulary employed to describe the resources is [CIDOC-CRM](https://cidoc-crm.org/).\n",
    "\n",
    "The following illustration shows how we modelled the outputs of this work in order to be integrated into the ECCCH.\n",
    "<img width=\"80%\" src=\"imgs/eccch-integration-steps.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c62f42-3aed-4662-9eb1-a071e8d535a0",
   "metadata": {},
   "source": [
    "And the following picture shows how we modelled the data using the vocabularies and ontologies. The class prov:Entity represents the code in the form of Jupyter Notebook which was generated by means of a prov:Activity, describing the work in this code, using a distribution of a dataset as an input (txt), and generating another distribution (ttl). The distributions are part of a dataset, which is also part of a catalog that was published by an organization.\n",
    "\n",
    "<img width=\"80%\" src=\"imgs/data-model-cidoc.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa11ae9-097d-4b26-9981-6ad2855bd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import FOAF, RDF, RDFS, DCTERMS, VOID, DC, SKOS, OWL, XSD\n",
    "import datetime\n",
    "\n",
    "g = Graph()\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"rdf\", RDF)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"dc\", DC)\n",
    "g.bind(\"void\", VOID)\n",
    "g.bind(\"skos\", SKOS)\n",
    "g.bind(\"owl\", OWL)\n",
    "\n",
    "schema = Namespace(\"https://schema.org/\")\n",
    "g.bind(\"schema\", schema)\n",
    "\n",
    "dcat = Namespace(\"http://www.w3.org/ns/dcat#\")\n",
    "g.bind(\"dcat\", dcat)\n",
    "\n",
    "wd = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "g.bind(\"wd\", wd)\n",
    "\n",
    "cidoc_crm = Namespace(\"http://www.cidoc-crm.org/cidoc-crm/\")\n",
    "g.bind(\"cidoc-crm\", cidoc_crm)\n",
    "\n",
    "prov = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "g.bind(\"prov\", prov)\n",
    "\n",
    "domain = 'https://example.org/'\n",
    "domainLanguage = domain + 'map/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa0feb-cf32-4271-a67d-de3bc26ccacf",
   "metadata": {},
   "source": [
    "##### We add the metadata of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d48953a0-72cb-482d-91cd-eb628c638db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create all the required URIS\n",
    "ai_catalog = URIRef(domain + \"catalog/ai\")\n",
    "ai_org = URIRef(domain + \"organization/ai\")\n",
    "ai_dataset = URIRef(domain + \"dataset/ai\")\n",
    "ai_ttl = URIRef(domain + \"distribution/ai-ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c5facef-6a75-4bf4-8bea-e405ce148136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf22eb6a8cb8541fbb1a0ce33e1047c72 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We describe the dataset\n",
    "g.add((ai_catalog, RDF.type, schema.Dataset))\n",
    "g.add((ai_catalog, RDF.type, dcat.catalog))\n",
    "g.add((ai_catalog, RDFS.label, Literal(\"AI preservation examples\")))\n",
    "g.add((ai_catalog, schema.description, Literal(\"This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks.\")))\n",
    "g.add((ai_catalog, schema.name, Literal(\"This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks.\")))\n",
    "g.add((ai_catalog, DCTERMS.title, Literal(\"This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks.\")))\n",
    "g.add((ai_catalog, DCTERMS.publisher, URIRef(ai_org))) # relation dataset-publisher\n",
    "g.add((ai_catalog, DC.title, Literal(\"OpenAIRE\")))\n",
    "g.add((ai_catalog, schema.license, URIRef('https://creativecommons.org/licenses/by/4.0/')))\n",
    "g.add((ai_catalog, dcat.dataset, ai_dataset))\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "g.add((ai_catalog, schema.dateCreated, Literal(str(now)[:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73df0ee6-2f75-4d6d-904a-fae65238968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf22eb6a8cb8541fbb1a0ce33e1047c72 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We describe a working group from glamlabs.io\n",
    "g.add((ai_org, RDF.type, FOAF.Organization))\n",
    "g.add((ai_org, RDFS.label, Literal(\"AI preservation group\")))\n",
    "g.add((ai_org, FOAF.homepage, URIRef(\"https://glamlabs.io/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d5d5dd3-dc40-4cf0-a133-3df637aaa0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf22eb6a8cb8541fbb1a0ce33e1047c72 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We describe the dataset\n",
    "g.add((ai_dataset, RDF.type, dcat.Dataset))\n",
    "g.add((ai_dataset, DCTERMS.title, Literal(\"LLM model to generate model cards and datasheets for AI models\", lang=\"en\")))\n",
    "g.add((ai_dataset, dcat.keyword, Literal(\"Research products\")))\n",
    "g.add((ai_dataset, dcat.keyword, Literal(\"LLM\")))\n",
    "g.add((ai_dataset, dcat.keyword, Literal(\"Data\")))\n",
    "g.add((ai_dataset, DCTERMS.issued, Literal(str(now)[:10])))\n",
    "g.add((ai_dataset, DCTERMS.language, URIRef(\"http://id.loc.gov/vocabulary/iso639-1/en\")))\n",
    "g.add((ai_dataset, dcat.distribution, URIRef(ai_ttl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b1b4390-3632-4f01-889b-14a55df5a459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf22eb6a8cb8541fbb1a0ce33e1047c72 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We describe the TTL distribution \n",
    "g.add((ai_ttl, RDF.type, dcat.Distribution))\n",
    "g.add((ai_ttl, dcat.downloadURL , URIRef(\"https://raw.githubusercontent.com/hibernator11/eccch-use-cases/refs/heads/main/data/ai/dataset_ai.ttl\")))\n",
    "g.add((ai_ttl, DCTERMS.title, Literal(\"TTL distribution of AI preservation\", lang=\"en\")))\n",
    "g.add((ai_ttl, DCTERMS.title, Literal(\"Distribución en TTL del conjunto de datos de AI preservation\", lang=\"es\")))\n",
    "g.add((ai_ttl, dcat.mediaType, URIRef(\"http://www.iana.org/assignments/media-types/application/n-triples\")))\n",
    "g.add((ai_ttl, dcat.byteSize, Literal('260000', datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32e7a3-46e8-4883-9216-d692b47d1248",
   "metadata": {},
   "source": [
    "### Now we link the notebooks and the distributions of the dataset created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fbab25b-df5c-44ad-b0c7-8869569ad99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf22eb6a8cb8541fbb1a0ce33e1047c72 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preservation_work = URIRef(domain + \"preservation-work/openaire\")\n",
    "notebooks = URIRef(domain + \"notebooks/openaire\")\n",
    "g.add((notebooks, RDF.type, prov.Entity))\n",
    "g.add((notebooks, DCTERMS.title, Literal(\"AI preservation\", lang=\"en\")))\n",
    "g.add((notebooks, prov.wasGeneratedBy, URIRef(preservation_work)))\n",
    "g.add((notebooks, dcat.mediatype, URIRef(\"https://www.iana.org/assignments/media-types/application/x-ipynb+json\")))\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "g.add((preservation_work, RDF.type, prov.Activity))\n",
    "g.add((preservation_work, prov.startedAtTime, Literal(str(now)[:10])))\n",
    "g.add((preservation_work, prov.generated, URIRef(ai_ttl)))\n",
    "g.add((preservation_work, prov.endedAtTime, Literal(str(now)[:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c8bce-1502-4859-914d-926dfaf28291",
   "metadata": {},
   "source": [
    "#### Store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87845933-19b1-4feb-946a-e2648c1251fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf22eb6a8cb8541fbb1a0ce33e1047c72 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination=\"data/ai/dataset_ai.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888eac86-ce8b-46eb-878a-37f2db05bfe2",
   "metadata": {},
   "source": [
    "#### Now we can query the graph using SPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2d6a9f6-bf7c-4e2e-88cf-5f10572cdca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Properties:\n",
      "http://www.w3.org/ns/dcat#downloadURL\n",
      "http://www.w3.org/ns/dcat#byteSize\n",
      "http://purl.org/dc/terms/title\n",
      "https://schema.org/name\n",
      "http://www.w3.org/ns/dcat#dataset\n",
      "http://www.w3.org/ns/prov#wasGeneratedBy\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "http://www.w3.org/ns/prov#generated\n",
      "https://schema.org/license\n",
      "http://www.w3.org/2000/01/rdf-schema#label\n",
      "http://www.w3.org/ns/dcat#distribution\n",
      "https://schema.org/dateCreated\n",
      "http://www.w3.org/ns/prov#startedAtTime\n",
      "http://www.w3.org/ns/dcat#keyword\n",
      "http://purl.org/dc/terms/language\n",
      "http://purl.org/dc/elements/1.1/title\n",
      "http://www.w3.org/ns/dcat#mediatype\n",
      "http://purl.org/dc/terms/publisher\n",
      "https://schema.org/description\n",
      "http://www.w3.org/ns/prov#endedAtTime\n",
      "http://purl.org/dc/terms/issued\n",
      "http://xmlns.com/foaf/0.1/homepage\n",
      "http://www.w3.org/ns/dcat#mediaType\n"
     ]
    }
   ],
   "source": [
    "print('##### Properties:')\n",
    "\n",
    "# Query the data in g using SPARQL\n",
    "q = \"\"\"\n",
    "    SELECT distinct ?prop\n",
    "    WHERE {\n",
    "        ?s ?prop ?o .\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Apply the query to the graph and iterate through results\n",
    "for r in g.query(q):\n",
    "    print(r[\"prop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8731b-ce35-4f13-92a6-844c785ac5b2",
   "metadata": {},
   "source": [
    "As an example we can retrieve the metadata of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5fd83d7-75d9-4759-a0c6-3686952a7e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type:  does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type: https://schema.org/Dataset does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type: https://schema.org/Dataset does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type:  does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://www.w3.org/ns/dcat#catalog does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://www.w3.org/ns/dcat#catalog does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/2000/01/rdf-schema#label:  does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/2000/01/rdf-schema#label: AI preservation examples does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/description:  does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/description: This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks. does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/name:  does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/name: This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks. does not look like a valid URI, trying to serialize this will break.\n",
      "http://purl.org/dc/terms/title:  does not look like a valid URI, trying to serialize this will break.\n",
      "http://purl.org/dc/terms/title: This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks. does not look like a valid URI, trying to serialize this will break.\n",
      "http://purl.org/dc/terms/publisher:  does not look like a valid URI, trying to serialize this will break.\n",
      "http://purl.org/dc/terms/publisher: https://example.org/organization/ai does not look like a valid URI, trying to serialize this will break.\n",
      "http://purl.org/dc/terms/publisher: https://example.org/organization/ai does not look like a valid URI, trying to serialize this will break.\n",
      "http://purl.org/dc/elements/1.1/title:  does not look like a valid URI, trying to serialize this will break.\n",
      "http://purl.org/dc/elements/1.1/title: OpenAIRE does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/license:  does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/license: https://creativecommons.org/licenses/by/4.0/ does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/license: https://creativecommons.org/licenses/by/4.0/ does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/ns/dcat#dataset:  does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/ns/dcat#dataset: https://example.org/dataset/ai does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.w3.org/ns/dcat#dataset: https://example.org/dataset/ai does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/dateCreated:  does not look like a valid URI, trying to serialize this will break.\n",
      "https://schema.org/dateCreated: 2026-01-22 does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Dataset information:\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type: https://schema.org/Dataset\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://www.w3.org/ns/dcat#catalog\n",
      "http://www.w3.org/2000/01/rdf-schema#label: AI preservation examples\n",
      "https://schema.org/description: This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks.\n",
      "https://schema.org/name: This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks.\n",
      "http://purl.org/dc/terms/title: This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks.\n",
      "http://purl.org/dc/terms/publisher: https://example.org/organization/ai\n",
      "http://purl.org/dc/elements/1.1/title: OpenAIRE\n",
      "https://schema.org/license: https://creativecommons.org/licenses/by/4.0/\n",
      "http://www.w3.org/ns/dcat#dataset: https://example.org/dataset/ai\n",
      "https://schema.org/dateCreated: 2026-01-22\n"
     ]
    }
   ],
   "source": [
    "print('##### Dataset information:')\n",
    "\n",
    "# Query the data in g using SPARQL\n",
    "q = \"\"\"\n",
    "    PREFIX schema: <https://schema.org/>\n",
    "    SELECT distinct ?p ?o\n",
    "    WHERE {\n",
    "        ?s a schema:Dataset .\n",
    "        ?s ?p ?o\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Apply the query to the graph and iterate through results\n",
    "for r in g.query(q):\n",
    "    print(r[\"p\"] + \": \" + r[\"o\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa4d35-19cd-4492-a7f6-234822b78501",
   "metadata": {},
   "source": [
    "#### Finally, we can use the ECCCH API to publish the data generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2f0b90-a832-4023-888e-9497512774bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Be done!\n",
    "# Integration with the ECCCH once the API and fina data model is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce75c2-6d6d-40e4-8207-ae632f1a29df",
   "metadata": {},
   "source": [
    "### Publication & dissemination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7bfb7-0f01-49ec-ac81-329687a1f604",
   "metadata": {},
   "source": [
    "This step involves the publication of the results obtained including the dataset and this notebook in different platforms such as the Social Sciences and Humanities Open Marketplace and Zenodo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b798c0-78a6-4ef1-a43f-8369fe5c98a0",
   "metadata": {},
   "source": [
    "As an example, we will use the sandbox service of Zenodo. Note that if you want to use this code for production purposes, it is required to update the URL. First, we need to create an access token in this [link](https://zenodo.org/account/settings/applications/tokens/new/). Note that we also need a token for the sandbox Zenodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34383f1d-a27f-4ce8-bfb0-285049f3b141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': '2026-01-12T17:41:07.632652+00:00',\n",
       " 'modified': '2026-01-12T17:41:07.740296+00:00',\n",
       " 'id': 424692,\n",
       " 'conceptrecid': '424691',\n",
       " 'metadata': {'access_right': 'open',\n",
       "  'prereserve_doi': {'doi': '10.5281/zenodo.424692', 'recid': 424692}},\n",
       " 'title': '',\n",
       " 'links': {'self': 'https://sandbox.zenodo.org/api/deposit/depositions/424692',\n",
       "  'html': 'https://sandbox.zenodo.org/deposit/424692',\n",
       "  'badge': 'https://sandbox.zenodo.org/badge/doi/.svg',\n",
       "  'files': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/files',\n",
       "  'bucket': 'https://sandbox.zenodo.org/api/files/a40e829f-dd24-4e7b-b228-7c4e048a270c',\n",
       "  'latest_draft': 'https://sandbox.zenodo.org/api/deposit/depositions/424692',\n",
       "  'latest_draft_html': 'https://sandbox.zenodo.org/deposit/424692',\n",
       "  'publish': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/actions/publish',\n",
       "  'edit': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/actions/edit',\n",
       "  'discard': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/actions/discard',\n",
       "  'newversion': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/actions/newversion'},\n",
       " 'record_id': 424692,\n",
       " 'owner': 52734,\n",
       " 'files': [],\n",
       " 'state': 'unsubmitted',\n",
       " 'submitted': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://developers.zenodo.org/\n",
    "import requests\n",
    "ACCESS_TOKEN = 'ChangeMe'\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "}\n",
    "r = requests.post('https://sandbox.zenodo.org/api/deposit/depositions',\n",
    "                   json={},\n",
    "                   headers=headers)\n",
    "r.status_code\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c958254-9d53-4f9a-ad9d-8d08d77a19aa",
   "metadata": {},
   "source": [
    "Now, let’s upload a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0b40f9e-0d8c-4a57-b4cf-6b719090a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_url = r.json()[\"links\"][\"bucket\"]\n",
    "deposition_id = r.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1c1a9-c108-4f39-ab66-658ab9649f9d",
   "metadata": {},
   "source": [
    "First, we create a zip file with the notebook and the requirements.txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f57f721d-ae80-4983-b176-11d499e9914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# List of files to include in the archive\n",
    "file_list = [\"AI-Preservation.ipynb\", \"requirements.txt\"]\n",
    "\n",
    "# Create ZIP file and write files into it\n",
    "with ZipFile(\"output.zip\", \"w\") as zipf:\n",
    "   for file in file_list:\n",
    "      zipf.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e7ae7-825a-42a5-95e5-3500a8aa8ab1",
   "metadata": {},
   "source": [
    "Then, we call the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66746842-a9e8-449b-b350-0fcdfe75a72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': '2026-01-12T17:41:16.912746+00:00',\n",
       " 'updated': '2026-01-12T17:41:17.052565+00:00',\n",
       " 'version_id': 'f8cd6099-25aa-4105-aa41-91921a295466',\n",
       " 'key': 'output.zip',\n",
       " 'size': 28194,\n",
       " 'mimetype': 'application/zip',\n",
       " 'checksum': 'md5:4df29214004c115c3e7a0ab4a433da97',\n",
       " 'is_head': True,\n",
       " 'delete_marker': False,\n",
       " 'links': {'self': 'https://sandbox.zenodo.org/api/files/a40e829f-dd24-4e7b-b228-7c4e048a270c/output.zip',\n",
       "  'version': 'https://sandbox.zenodo.org/api/files/a40e829f-dd24-4e7b-b228-7c4e048a270c/output.zip?version_id=f8cd6099-25aa-4105-aa41-91921a295466',\n",
       "  'uploads': 'https://sandbox.zenodo.org/api/files/a40e829f-dd24-4e7b-b228-7c4e048a270c/output.zip?uploads=1'}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"output.zip\"\n",
    "path = \"%s\" % filename\n",
    "headers = {'Authorization': f'Bearer {ACCESS_TOKEN}'}\n",
    "\n",
    "''' \n",
    "The target URL is a combination of the bucket link with the desired filename\n",
    "seperated by a slash.\n",
    "'''\n",
    "with open(path, \"rb\") as fp:\n",
    "    r = requests.put(\n",
    "        \"%s/%s\" % (bucket_url, filename),\n",
    "        data=fp,\n",
    "        headers=headers,\n",
    "    )\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7c646-2d78-4632-ab89-7edd1d559f30",
   "metadata": {},
   "source": [
    "We can also add metadata to the record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e08090fd-7987-423a-80da-f8b7cebda1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "     'metadata': {\n",
    "         'title': 'AI Preservation',\n",
    "         'upload_type': 'software',\n",
    "         'description': 'This use case will explore how to approach the long-term preservation of AI models which are contributing to notebooks',\n",
    "         'creators': [{'name': 'Candela, Gustavo',\n",
    "                       'affiliation': 'University of Alicante'}]\n",
    "     }\n",
    " }\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {ACCESS_TOKEN}'\n",
    "}\n",
    "r = requests.put('https://sandbox.zenodo.org/api/deposit/depositions/%s' % deposition_id,\n",
    "                  data=json.dumps(data),\n",
    "                  headers=headers)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2607fc-4ae0-4a4c-b6ad-b7f6f1e9fb20",
   "metadata": {},
   "source": [
    "The last step is the publication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbfe2229-46fe-4704-930c-7e50c44b09fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'Authorization': f'Bearer {ACCESS_TOKEN}'}\n",
    "r = requests.post('https://sandbox.zenodo.org/api/deposit/depositions/%s/actions/publish' % deposition_id,\n",
    "                      headers=headers)\n",
    "r.status_code\n",
    "# 202"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e029f6-ac09-4beb-9949-c49b3e72dd5e",
   "metadata": {},
   "source": [
    "And now we can see the result in Zenodo:\n",
    "\n",
    "<img src=\"imgs/zenodo-publication.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d848c-ffd3-4320-b5e5-7736e59d0523",
   "metadata": {},
   "source": [
    "We can reproduce the same with additional platforms such as [Wikidata](https://www.wikidata.org/) and the [Social Sciences and Humanities Open Marketplace](https://marketplace.sshopencloud.eu/about/api-documentation)\n",
    "\n",
    "In the particular case of Wikidata, existing [python libraries](https://www.mediawiki.org/wiki/Manual:Pywikibot/Wikidata) can be used to extract and create entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc50cf-5160-4c2d-9750-34c6a7afa241",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Candela, G., Rosiński, C., & Margraf, A. (2025). A reproducible framework to publish and reuse Collections as data: the case of the European Literary Bibliography (Version 4, Vol. 965, Issue 170). Transformations: A DARIAH Journal . https://doi.org/10.46298/transformations.14729\n",
    "- Gustavo Candela, Javier Pereda, Dolores Sáez, Pilar Escobar, Alexander Sánchez, Andrés Villa Torres, Albert A. Palacios, Kelly McDonough, and Patricia Murrieta-Flores. 2023. An Ontological Approach for Unlocking the Colonial Archive. J. Comput. Cult. Herit. 16, 4, Article 74 (December 2023), 18 pages. https://doi.org/10.1145/3594727\n",
    "- Jiarui Liu, Wenkai Li, Zhijing Jin, and Mona Diab. 2024. Automatic Generation of Model and Data Cards: A Step Towards Responsible AI. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 1975–1997, Mexico City, Mexico. Association for Computational Linguistics.\n",
    "- https://developers.zenodo.org/#quickstart-upload\n",
    "- https://www.echoes-eccch.eu/wp-content/uploads/2025/06/ECHOES_HDT_Ontology.pdf\n",
    "- https://marketplace.sshopencloud.eu/about/api-documentation\n",
    "- https://www.wikidata.org/\n",
    "- https://cidoc-crm.org/sites/default/files/CRMdigv4.0.pdf\n",
    "- https://www.w3.org/TR/prov-o/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
