{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba4d84e-ae47-475b-941d-462fd8f3c43b",
   "metadata": {},
   "source": [
    "# Application of notebooks in digital twins\n",
    "\n",
    "This use case will demonstrate how data relevant to various digital twins models can be supported by notebooks to provide examples of use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295e10c-b8e4-41c9-929a-1201023901e0",
   "metadata": {},
   "source": [
    "This approach employs a workflow as shown in the following picture.\n",
    "\n",
    "<img src=\"imgs/workflow.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68660bce-3a5b-461d-a11a-410e1101090d",
   "metadata": {},
   "source": [
    "### Available Datasets \n",
    "\n",
    "This section describes existing collections of maps made available by relevant institutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6c9ff-4f2f-4c48-8997-19a24c485b86",
   "metadata": {},
   "source": [
    "For instance, [KU Leuven Libraries](https://bib.kuleuven.be/english/heritage/heritagecollections/types-of-material/maps-and-atlases) hosts more than 20,000 maps and atlases with a focus on Belgian territory from the 16th century to the present. These materials show us how the landscape used to look and thus offer essential information for geographers and historians. They provide [documentation](https://bib.kuleuven.be/english/heritage/how-to-search/how-to-search-maps) to show how to access and search the maps.\n",
    "\n",
    "<img width=\"30%\" src=\"https://bib.kuleuven.be/bijzondere-collecties/images/erfgoed_oude_drukken/r3a-19840-000332.jpg/@@images/image-400-aaaa9986e11af72ae305e9b4e829de13.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab00fd-1844-4b52-991c-b6b9e899e062",
   "metadata": {},
   "source": [
    "The [Royal Danish Library](https://www.kb.dk/en/find-materials/collections/map-collection) also provides access to a collection of maps. The oldest maps in the collection date from the 16th century. For example, by using the [following link](https://soeg.kb.dk/discovery/search?query=any,contains,danmark&tab=Everything&search_scope=MyInst_and_CI&vid=45KBDK_KGL:KGL&facet=rtype,include,maps&lang=en&offset=10&came_from=pagination_1_2), we can retrieve maps related to Denmark. The following image shows an example.\n",
    "\n",
    "<img width=\"50%\" src=\"https://kb-images.kb.dk/DAMJP2/DAM/Maps/0000/069/459/DK003600/full/full/0/native.jpg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cc155b1-8a48-45a6-8bb8-642ee6d523eb",
   "metadata": {},
   "source": [
    "The [National Library of Spain](https://bnedigital.bne.es/bd/es/results?y=s&o=&o=&w=mapa&w=&f=ficha&f=texto_ficha&g=ws&f4=Material+cartogr%C3%A1fico+manuscrito) provides access to a collection of maps, including textual metadata, that can be exported as a txt file. The [following link](https://bnedigital.bne.es/bd/es/export?y=s&o=&o=&w=mapa&w=&f=ficha&f=texto_ficha&g=ws&f4=Material+cartogr%C3%A1fico+manuscrito&x=adefadbf-b10b-4a34-a0d7-98513056a7b3) provides access to the metadata of the collection extracted as textual documentation. Note that most of the records are provided under a CC0 licence.\n",
    "\n",
    "<img width=\"30%\" src=\"https://bnedigital.bne.es/bd/es/medium?id=d5a51609-f45a-48f0-836e-1bffe32430f7\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe14f4-eeb3-49f4-9eeb-77a786c23744",
   "metadata": {},
   "source": [
    "Here we can see an overview the metadata provided by the National Library of Spain. As we can see the metadata is limited to the title, authors, dates and some notes.\n",
    "\n",
    "```\n",
    "Registro 1\n",
    "\n",
    "    Título:              [Mapa itinerario de Guipúzcoa]\n",
    "\n",
    "    Tipo de documento:   Material cartográfico manuscrito\n",
    "\n",
    "    Autoría:             \n",
    "\n",
    "    Fecha:               [18­-]\n",
    "\n",
    "    Materia:             \n",
    "\n",
    "    Descripción física:  1 mapa : ms., col.\n",
    "\n",
    "    Signatura:           MR/42/471\n",
    "\n",
    "    MMS ID:              991000586059708606\n",
    "\n",
    "    Identificador corto: 0174194456\n",
    "\n",
    "    CDU:                 (466.2)\n",
    "\n",
    "    URL:                 https://bnedigital.bne.es/bd/es/card?id=2d3c9301-a1d1-45de-ae3c-8d7c5c02221c\n",
    "------------------------------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f21e5-03ee-4c80-bdf1-742ec250e8ae",
   "metadata": {},
   "source": [
    "## We will use the National Library of Spain as example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223f21f-63a9-49d0-bd9c-15c203b9bbc7",
   "metadata": {},
   "source": [
    "### Retrieve Metadata\n",
    "\n",
    "This step involves the retrievement of the metadata from the National Library of Spain. The web interface was employed to search the records typed as cartographic material. Then, the export link was used to download the metadata which corresponds to a text and human-readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b79203d-cb70-4708-a4bf-63d1238ce30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://bnedigital.bne.es/bd/es/export?o=&o=o&o=n&o=&o=o&o=n&w=&w=&w=&w=&w=&w=&f=ficha&f=ficha&f=ficha&f=ficha&f=ficha&f=ficha&p=&f4=Material+cartogr%C3%A1fico+manuscrito&g=ws&g=dd&g=ld&g=pd&g=pg&g=hh&g=fa&d=date&d=&d=&startYear=&endYear=&year=&l=10&x=adefadbf-b10b-4a34-a0d7-98513056a7b3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4e0773c-b413-4b83-9081-352063802dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "resp = requests.get(url=url)\n",
    "#print (resp.text) ## uncomment to see the content\n",
    "\n",
    "with open(\"data/maps-bne/metadata-bne.txt\", \"w\") as text_file:\n",
    "    text_file.write(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e56feb-25fb-47d4-9486-cdf944698bf9",
   "metadata": {},
   "source": [
    "#### Extraction\n",
    "\n",
    "Now we transform the human-readable text to a CSV so the data can be analysed and adapted easily. For this, we create a CSV file, each row containing a record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21cdfd0d-39a6-4968-a3e1-220414fc7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtfile = \"data/maps-bne/metadata-bne.txt\"\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data/maps-bne/metadata-bne.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    field = [\"title\", \"type\", \"author\", \"date\", \"subject\", \"description\", \"id\", \"url\"]\n",
    "    writer.writerow(field)\n",
    "\n",
    "    title = author = date = subject = description = id = url = ''\n",
    "    \n",
    "    with open(txtfile) as file: # loop all the rows and add the metadata fields\n",
    "        for line in file:\n",
    "            #print(line.rstrip())\n",
    "            if \"Identificador corto\" in line:\n",
    "                id = line.split(\": \")[1]\n",
    "                #print(\"id:\" + id)\n",
    "            elif \"Título:\" in line:\n",
    "                title = line.split(\": \")[1]\n",
    "                #print(\"title:\" + title)\n",
    "            elif \"Autoría\" in line:\n",
    "                author = line.split(\": \")[1]\n",
    "                #print(\"author:\" + author)\n",
    "            elif \"Descripción física\" in line:\n",
    "                description = line[line.index(\":\"):]\n",
    "                #print(\"description:\" + description)\n",
    "            elif \"Materia:\" in line:\n",
    "                subject = line.split(\": \")[1]\n",
    "                #print(\"subject:\" + subject)\n",
    "            elif \"Fecha:\" in line:\n",
    "                date = line.split(\": \")[1]\n",
    "            elif \"URL:\" in line: # last field of each record\n",
    "                url = line.split(\": \")[1]\n",
    "                #print(\"url:\" + url)\n",
    "                writer.writerow([title,\"map\",author,date,subject,description,id,url])\n",
    "                title = author = date = subject = description = id = url = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688c05c-4961-4b6f-840d-2bad76214528",
   "metadata": {},
   "source": [
    "### Extract OCR from images\n",
    "\n",
    "For the text extraction we are going to use a LLM approach, in particular, Ollama. We will test additional LLMs such as llava, deepseek, Mistral and QWEN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3851f9-c087-44dd-ad90-b4ffe1fd2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama-ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf575fdd-0c1e-4fee-b1f6-3993a4905b25",
   "metadata": {},
   "source": [
    "https://bnedigital.bne.es/bd/card?oid=0000000735\n",
    "https://bnedigital.bne.es/bd/card?oid=0000001402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea958ebc-5a18-4db1-b6ee-2989b6d32ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_ocr import OCRProcessor\n",
    "\n",
    "# Initialize OCR processor\n",
    "ocr = OCRProcessor(model_name='llama3.2-vision:11b')  # You can use any vision model available on Ollama\n",
    "#ocr = OCRProcessor(model_name='llava:7b')\n",
    "ocr = OCRProcessor(model_name='deepseek-ocr')\n",
    "\n",
    "# Process an image\n",
    "result = ocr.process_image(\n",
    "    image_path=\"imgs/Isle-Saint-Domingue.jpg\",\n",
    "    format_type=\"markdown\"  # Options: markdown, text, json, structured, key_value\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737e237-200d-4a42-a86c-79d5c1556cc1",
   "metadata": {},
   "source": [
    "### Transform the metadata to RDF\n",
    "\n",
    "In this step we transform the human-readable metadata to machine-readable by using [Resource Description Framework (RDF)](https://www.w3.org/TR/rdf12-concepts/), a standard to publish data in the form of triplets promoted by the W3C.\n",
    "\n",
    "Following other approaches and previous work, the python library RDFLib is employed to create the RDF data by means of Schema.org as main vocabulary.\n",
    "\n",
    "Note that as an example we use the National Library of Spain. Additional datasets could be used following a similar approach, in order to create a larger dataset with data integrated from several institutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa11ae9-097d-4b26-9981-6ad2855bd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import FOAF, RDF, RDFS, DCTERMS, VOID, DC, SKOS, OWL, XSD\n",
    "import datetime\n",
    "\n",
    "g = Graph()\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"rdf\", RDF)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"dc\", DC)\n",
    "g.bind(\"void\", VOID)\n",
    "g.bind(\"skos\", SKOS)\n",
    "g.bind(\"owl\", OWL)\n",
    "\n",
    "schema = Namespace(\"https://schema.org/\")\n",
    "g.bind(\"schema\", schema)\n",
    "\n",
    "dcat = Namespace(\"http://www.w3.org/ns/dcat#\")\n",
    "g.bind(\"dcat\", dcat)\n",
    "\n",
    "wd = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "g.bind(\"wd\", wd)\n",
    "\n",
    "domain = 'https://example.org/'\n",
    "domainLanguage = domain + 'map/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa0feb-cf32-4271-a67d-de3bc26ccacf",
   "metadata": {},
   "source": [
    "##### We add the metadata of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d48953a0-72cb-482d-91cd-eb628c638db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create all the required URIS\n",
    "catalog = URIRef(domain + \"catalog/digital-twins\")\n",
    "bne = URIRef(domain + \"organization/bneXXXXXXXXXXXXXXXXXXXX\")\n",
    "dataset = URIRef(domain + \"dataset/digital-twins\")\n",
    "digital_twins_csv = URIRef(domain + \"distribution/digital-twins-csv\")\n",
    "digital_twins_ttl = URIRef(domain + \"distribution/digital-twins-ttl\")\n",
    "digital_twins_txt = URIRef(domain + \"distribution/digital-twins-txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c5facef-6a75-4bf4-8bea-e405ce148136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ne8c3760cc88544b3a0b3abc64fab124e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We describe the dataset\n",
    "g.add((catalog, RDF.type, schema.Dataset))\n",
    "g.add((catalog, RDF.type, dcat.catalog))\n",
    "g.add((catalog, RDFS.label, Literal(\"Maps from the National Library of Spain\")))\n",
    "g.add((catalog, schema.url, URIRef(\"https://bnedigital.bne.es/\")))\n",
    "g.add((catalog, FOAF.homepage, URIRef(\"https://bnedigital.bne.es/\")))\n",
    "g.add((catalog, schema.description, Literal(\"Maps from the National Library of Spain\")))\n",
    "g.add((catalog, schema.name, Literal(\"Maps from the National Library of Spain\")))\n",
    "g.add((catalog, DCTERMS.title, Literal(\"Maps from the National Library of Spain\")))\n",
    "g.add((catalog, DCTERMS.publisher, URIRef(bne))) # relation dataset-publisher\n",
    "g.add((catalog, DC.title, Literal(\"National Library of Spain\")))\n",
    "g.add((catalog, schema.license, URIRef('https://creativecommons.org/publicdomain/zero/1.0/')))\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "g.add((catalog, schema.dateCreated, Literal(str(now)[:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73df0ee6-2f75-4d6d-904a-fae65238968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ne8c3760cc88544b3a0b3abc64fab124e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We describe the BNE\n",
    "g.add((bne, RDF.type, FOAF.Organization))\n",
    "g.add((bne, RDFS.label, Literal(\"National Library of Spain\")))\n",
    "g.add((bne, FOAF.homepage, URIRef(\"https://bnedigital.bne.es/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d5d5dd3-dc40-4cf0-a133-3df637aaa0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ne8c3760cc88544b3a0b3abc64fab124e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We describe the dataset\n",
    "g.add((dataset, RDF.type, dcat.Dataset))\n",
    "g.add((dataset, DCTERMS.title, Literal(\"Maps from the National Library of Spain\", lang=\"en\")))\n",
    "g.add((dataset, dcat.keyword, Literal(\"Maps\")))\n",
    "g.add((dataset, dcat.keyword, Literal(\"Cartographic material\")))\n",
    "g.add((dataset, dcat.keyword, Literal(\"Collections as data\")))\n",
    "g.add((dataset, DCTERMS.issued, Literal(str(now)[:10])))\n",
    "g.add((dataset, DCTERMS.language, URIRef(\"http://id.loc.gov/vocabulary/iso639-1/es\")))\n",
    "g.add((dataset, dcat.distribution, URIRef(digital_twins_csv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b1b4390-3632-4f01-889b-14a55df5a459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ne8c3760cc88544b3a0b3abc64fab124e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We describe the distributions CSV and TTL \n",
    "g.add((digital_twins_csv, RDF.type, dcat.Distribution))\n",
    "g.add((digital_twins_csv, dcat.downloadURL , URIRef(\"https://raw.githubusercontent.com/hibernator11/eccch-use-cases/refs/heads/main/data/maps-bne/metadata-bne.csv\")))\n",
    "g.add((digital_twins_csv, DCTERMS.title, Literal(\"CSV distribution of BNE cartographic material\", lang=\"en\")))\n",
    "g.add((digital_twins_csv, DCTERMS.title, Literal(\"Distribución en CSV del conjunto de datos de mapas de la BNE\", lang=\"es\")))\n",
    "g.add((digital_twins_csv, dcat.mediaType, URIRef(\"http://www.iana.org/assignments/media-types/text/csv\")))\n",
    "g.add((digital_twins_csv, dcat.byteSize, Literal('300000', datatype=XSD.integer)))\n",
    "\n",
    "g.add((digital_twins_ttl, RDF.type, dcat.Distribution))\n",
    "g.add((digital_twins_ttl, dcat.downloadURL , URIRef(\"https://raw.githubusercontent.com/hibernator11/eccch-use-cases/refs/heads/main/data/maps-bne/dataset_bne.ttl\")))\n",
    "g.add((digital_twins_ttl, DCTERMS.title, Literal(\"TTL distribution of BNE cartographic material\", lang=\"en\")))\n",
    "g.add((digital_twins_ttl, DCTERMS.title, Literal(\"Distribución en TTL del conjunto de datos de mapas de la BNE\", lang=\"es\")))\n",
    "g.add((digital_twins_ttl, dcat.mediaType, URIRef(\"http://www.iana.org/assignments/media-types/application/n-triples\")))\n",
    "g.add((digital_twins_ttl, dcat.byteSize, Literal('528000', datatype=XSD.integer)))\n",
    "\n",
    "g.add((digital_twins_txt, RDF.type, dcat.Distribution))\n",
    "g.add((digital_twins_txt, dcat.downloadURL , URIRef(\"https://raw.githubusercontent.com/hibernator11/eccch-use-cases/refs/heads/main/data/maps-bne/metadata-bne.txt\")))\n",
    "g.add((digital_twins_txt, DCTERMS.title, Literal(\"TXT distribution of BNE cartographic material\", lang=\"en\")))\n",
    "g.add((digital_twins_txt, DCTERMS.title, Literal(\"Distribución en TXT del conjunto de datos de mapas de la BNE\", lang=\"es\")))\n",
    "g.add((digital_twins_txt, dcat.mediaType, URIRef(\"https://www.iana.org/assignments/media-types/text/plain\")))\n",
    "g.add((digital_twins_txt, dcat.byteSize, Literal('671000', datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e1e99-ca13-4c88-a965-860c8738368b",
   "metadata": {},
   "source": [
    "#### Read the CSV file and transform the records\n",
    "Now we will transform the records using several classes and properties from differentes vocabularies and ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87845933-19b1-4feb-946a-e2648c1251fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/maps-bne/metadata-bne.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        #print(row['id'], row['type'])\n",
    "        \n",
    "        classtype = 'https://schema.org/CreativeWork'\n",
    "        \n",
    "        record = URIRef(domain + \"record/\" + str(row[\"id\"]).strip())\n",
    "        g.add((record, RDF.type, URIRef(classtype)))\n",
    "        g.add((record, schema.sourceOrganization, Literal(\"National Library of Spain\")))\n",
    "        g.add((record, schema.isPartOf, maps))\n",
    "        g.add((record, schema.description, Literal(row['description'].strip())))\n",
    "        if row['author'].strip() != \"\":\n",
    "            g.add((record, schema.author, Literal(row['author'].strip())))\n",
    "        g.add((record, schema.identifier, Literal(row['id'].strip())))\n",
    "        g.add((record, schema.datePublished, Literal(row['date'].strip())))\n",
    "        g.add((record, schema.name, Literal(row['title'].strip())))\n",
    "        g.add((record, schema.url, URIRef(row['url'].strip())))\n",
    "        g.add((record, schema.license, URIRef('https://creativecommons.org/publicdomain/zero/1.0/')))\n",
    "\n",
    "g.serialize(destination=\"data/maps-bne/dataset_bne.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888eac86-ce8b-46eb-878a-37f2db05bfe2",
   "metadata": {},
   "source": [
    "#### Now we can query the graph using SPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6a9f6-bf7c-4e2e-88cf-5f10572cdca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##### Properties:')\n",
    "\n",
    "# Query the data in g using SPARQL\n",
    "q = \"\"\"\n",
    "    SELECT distinct ?prop\n",
    "    WHERE {\n",
    "        ?s ?prop ?o .\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Apply the query to the graph and iterate through results\n",
    "for r in g.query(q):\n",
    "    print(r[\"prop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8731b-ce35-4f13-92a6-844c785ac5b2",
   "metadata": {},
   "source": [
    "As an example we can retrieve the metadata of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd83d7-75d9-4759-a0c6-3686952a7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##### Dataset information:')\n",
    "\n",
    "# Query the data in g using SPARQL\n",
    "q = \"\"\"\n",
    "    PREFIX schema: <https://schema.org/>\n",
    "    SELECT distinct ?p ?o\n",
    "    WHERE {\n",
    "        ?s a schema:Dataset .\n",
    "        ?s ?p ?o\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Apply the query to the graph and iterate through results\n",
    "for r in g.query(q):\n",
    "    print(r[\"p\"] + \": \" + r[\"o\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086b582-073d-492b-8fb7-e179f0154dde",
   "metadata": {},
   "source": [
    "### Integration with the ECCCH\n",
    "\n",
    "[ECHOES](https://www.echoes-eccch.eu/faq/) is building a federated Knowledge Graph to allow for high level integration of resources. It will also serve as an entry point for all queries and requests related to any kind of information available within the Cultural heritage Cloud. The Knowledge Graph will use the proposed Heritage Digital Twin Ontology (HDTO) to unify descriptions and facilitate query and navigation. The current version of the ECHOES HDTO is available [here](https://www.echoes-eccch.eu/wp-content/uploads/2025/06/ECHOES_HDT_Ontology.pdf). The main vocabulary employed to describe the resources is [CIDOC-CRM](https://cidoc-crm.org/).\n",
    "\n",
    "The following illustration shows how we modelled the outputs of this work in order to be integrated into the ECCCH.\n",
    "<img width=\"80%\" src=\"imgs/eccch-integration-steps.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2f0b90-a832-4023-888e-9497512774bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Be done!\n",
    "# Integration with the ECCCH once the API and fina data model is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce75c2-6d6d-40e4-8207-ae632f1a29df",
   "metadata": {},
   "source": [
    "### Publication & dissemination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7bfb7-0f01-49ec-ac81-329687a1f604",
   "metadata": {},
   "source": [
    "This step involves the publication of the results obtained including the dataset and this notebook in different platforms such as the Social Sciences and Humanities Open Marketplace and Zenodo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b798c0-78a6-4ef1-a43f-8369fe5c98a0",
   "metadata": {},
   "source": [
    "As an example, we will use the sandbox service of Zenodo. Note that if you want to use this code for production purposes, it is required to update the URL. First, we need to create an access token in this [link](https://zenodo.org/account/settings/applications/tokens/new/). Note that we also need a token for the sandbox Zenodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34383f1d-a27f-4ce8-bfb0-285049f3b141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': '2026-01-12T17:41:07.632652+00:00',\n",
       " 'modified': '2026-01-12T17:41:07.740296+00:00',\n",
       " 'id': 424692,\n",
       " 'conceptrecid': '424691',\n",
       " 'metadata': {'access_right': 'open',\n",
       "  'prereserve_doi': {'doi': '10.5281/zenodo.424692', 'recid': 424692}},\n",
       " 'title': '',\n",
       " 'links': {'self': 'https://sandbox.zenodo.org/api/deposit/depositions/424692',\n",
       "  'html': 'https://sandbox.zenodo.org/deposit/424692',\n",
       "  'badge': 'https://sandbox.zenodo.org/badge/doi/.svg',\n",
       "  'files': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/files',\n",
       "  'bucket': 'https://sandbox.zenodo.org/api/files/a40e829f-dd24-4e7b-b228-7c4e048a270c',\n",
       "  'latest_draft': 'https://sandbox.zenodo.org/api/deposit/depositions/424692',\n",
       "  'latest_draft_html': 'https://sandbox.zenodo.org/deposit/424692',\n",
       "  'publish': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/actions/publish',\n",
       "  'edit': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/actions/edit',\n",
       "  'discard': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/actions/discard',\n",
       "  'newversion': 'https://sandbox.zenodo.org/api/deposit/depositions/424692/actions/newversion'},\n",
       " 'record_id': 424692,\n",
       " 'owner': 52734,\n",
       " 'files': [],\n",
       " 'state': 'unsubmitted',\n",
       " 'submitted': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://developers.zenodo.org/\n",
    "import requests\n",
    "ACCESS_TOKEN = 'ChangeMe'\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "}\n",
    "r = requests.post('https://sandbox.zenodo.org/api/deposit/depositions',\n",
    "                   json={},\n",
    "                   headers=headers)\n",
    "r.status_code\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c958254-9d53-4f9a-ad9d-8d08d77a19aa",
   "metadata": {},
   "source": [
    "Now, let’s upload a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0b40f9e-0d8c-4a57-b4cf-6b719090a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_url = r.json()[\"links\"][\"bucket\"]\n",
    "deposition_id = r.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1c1a9-c108-4f39-ab66-658ab9649f9d",
   "metadata": {},
   "source": [
    "First, we create a zip file with the notebook and the requirements.txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f57f721d-ae80-4983-b176-11d499e9914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# List of files to include in the archive\n",
    "file_list = [\"Digital-Twins.ipynb\", \"requirements.txt\"]\n",
    "\n",
    "# Create ZIP file and write files into it\n",
    "with ZipFile(\"output.zip\", \"w\") as zipf:\n",
    "   for file in file_list:\n",
    "      zipf.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e7ae7-825a-42a5-95e5-3500a8aa8ab1",
   "metadata": {},
   "source": [
    "Then, we call the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66746842-a9e8-449b-b350-0fcdfe75a72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': '2026-01-12T17:41:16.912746+00:00',\n",
       " 'updated': '2026-01-12T17:41:17.052565+00:00',\n",
       " 'version_id': 'f8cd6099-25aa-4105-aa41-91921a295466',\n",
       " 'key': 'output.zip',\n",
       " 'size': 28194,\n",
       " 'mimetype': 'application/zip',\n",
       " 'checksum': 'md5:4df29214004c115c3e7a0ab4a433da97',\n",
       " 'is_head': True,\n",
       " 'delete_marker': False,\n",
       " 'links': {'self': 'https://sandbox.zenodo.org/api/files/a40e829f-dd24-4e7b-b228-7c4e048a270c/output.zip',\n",
       "  'version': 'https://sandbox.zenodo.org/api/files/a40e829f-dd24-4e7b-b228-7c4e048a270c/output.zip?version_id=f8cd6099-25aa-4105-aa41-91921a295466',\n",
       "  'uploads': 'https://sandbox.zenodo.org/api/files/a40e829f-dd24-4e7b-b228-7c4e048a270c/output.zip?uploads=1'}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"output.zip\"\n",
    "path = \"%s\" % filename\n",
    "headers = {'Authorization': f'Bearer {ACCESS_TOKEN}'}\n",
    "\n",
    "''' \n",
    "The target URL is a combination of the bucket link with the desired filename\n",
    "seperated by a slash.\n",
    "'''\n",
    "with open(path, \"rb\") as fp:\n",
    "    r = requests.put(\n",
    "        \"%s/%s\" % (bucket_url, filename),\n",
    "        data=fp,\n",
    "        headers=headers,\n",
    "    )\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7c646-2d78-4632-ab89-7edd1d559f30",
   "metadata": {},
   "source": [
    "We can also add metadata to the record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e08090fd-7987-423a-80da-f8b7cebda1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "     'metadata': {\n",
    "         'title': 'Using and reusing notebooks in high-performance computing environments',\n",
    "         'upload_type': 'software',\n",
    "         'description': 'This use case shows how to reuse a collections of maps made available by the National Library of Spain following a set of steps in the form of a reproducible workflow: extraction, OCR analysis using LLMs, metadata generation and dissemination',\n",
    "         'creators': [{'name': 'Candela, Gustavo',\n",
    "                       'affiliation': 'University of Alicante'}]\n",
    "     }\n",
    " }\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {ACCESS_TOKEN}'\n",
    "}\n",
    "r = requests.put('https://sandbox.zenodo.org/api/deposit/depositions/%s' % deposition_id,\n",
    "                  data=json.dumps(data),\n",
    "                  headers=headers)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2607fc-4ae0-4a4c-b6ad-b7f6f1e9fb20",
   "metadata": {},
   "source": [
    "The last step is the publication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbfe2229-46fe-4704-930c-7e50c44b09fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'Authorization': f'Bearer {ACCESS_TOKEN}'}\n",
    "r = requests.post('https://sandbox.zenodo.org/api/deposit/depositions/%s/actions/publish' % deposition_id,\n",
    "                      headers=headers)\n",
    "r.status_code\n",
    "# 202"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e029f6-ac09-4beb-9949-c49b3e72dd5e",
   "metadata": {},
   "source": [
    "And now we can see the result in Zenodo:\n",
    "\n",
    "<img src=\"imgs/zenodo-publication.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d848c-ffd3-4320-b5e5-7736e59d0523",
   "metadata": {},
   "source": [
    "We can reproduce the same with additional platforms such as [Wikidata](https://www.wikidata.org/) and the [Social Sciences and Humanities Open Marketplace](https://marketplace.sshopencloud.eu/about/api-documentation)\n",
    "\n",
    "In the particular case of Wikidata, existing [python libraries](https://www.mediawiki.org/wiki/Manual:Pywikibot/Wikidata) can be used to extract and create entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc50cf-5160-4c2d-9750-34c6a7afa241",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Candela, G., Rosiński, C., & Margraf, A. (2025). A reproducible framework to publish and reuse Collections as data: the case of the European Literary Bibliography (Version 4, Vol. 965, Issue 170). Transformations: A DARIAH Journal . https://doi.org/10.46298/transformations.14729\n",
    "- Gustavo Candela, Javier Pereda, Dolores Sáez, Pilar Escobar, Alexander Sánchez, Andrés Villa Torres, Albert A. Palacios, Kelly McDonough, and Patricia Murrieta-Flores. 2023. An Ontological Approach for Unlocking the Colonial Archive. J. Comput. Cult. Herit. 16, 4, Article 74 (December 2023), 18 pages. https://doi.org/10.1145/3594727\n",
    "- Niccolucci F, Markhoff B, Theodoridou M et al. The Heritage Digital Twin: a bicycle made for two. The integration of digital methodologies into cultural heritage research [version 1; peer review: 2 approved with reservations]. Open Res Europe 2023, 3:64 (https://doi.org/10.12688/openreseurope.15496.1)\n",
    "- https://developers.zenodo.org/#quickstart-upload\n",
    "- https://www.echoes-eccch.eu/wp-content/uploads/2025/06/ECHOES_HDT_Ontology.pdf\n",
    "- https://marketplace.sshopencloud.eu/about/api-documentation\n",
    "- https://www.wikidata.org/\n",
    "- https://cidoc-crm.org/sites/default/files/CRMdigv4.0.pdf\n",
    "- https://arxiv.org/html/2503.02167v1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
